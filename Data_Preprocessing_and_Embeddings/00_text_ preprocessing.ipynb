{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ac208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488ece44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrapped(text, max_cols=80):\n",
    "    wrapped = textwrap.fill(text, width=max_cols)\n",
    "    print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5671c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../DATA/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cafce339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape (m,n)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec7a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# display basic info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a626232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "141f6e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode\n",
      "you'll be hooked. They are right, as this is exactly what happened with me.<br\n",
      "/><br />The first thing that struck me about Oz was its brutality and\n",
      "unflinching scenes of violence, which set in right from the word GO. Trust me,\n",
      "this is not a show for the faint hearted or timid. This show pulls no punches\n",
      "with regards to drugs, sex or violence. Its is hardcore, in the classic use of\n",
      "the word.<br /><br />It is called OZ as that is the nickname given to the Oswald\n",
      "Maximum Security State Penitentary. It focuses mainly on Emerald City, an\n",
      "experimental section of the prison where all the cells have glass fronts and\n",
      "face inwards, so privacy is not high on the agenda. Em City is home to\n",
      "many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and\n",
      "more....so scuffles, death stares, dodgy dealings and shady agreements are never\n",
      "far away.<br /><br />I would say the main appeal of the show is due to the fact\n",
      "that it goes where other shows wouldn't dare. Forget pretty pictures painted for\n",
      "mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The\n",
      "first episode I ever saw struck me as so nasty it was surreal, I couldn't say I\n",
      "was ready for it, but as I watched more, I developed a taste for Oz, and got\n",
      "accustomed to the high levels of graphic violence. Not just violence, but\n",
      "injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill\n",
      "on order and get away with it, well mannered, middle class inmates being turned\n",
      "into prison bitches due to their lack of street skills or prison experience)\n",
      "Watching Oz, you may become comfortable with what is uncomfortable\n",
      "viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "# peek one review\n",
    "print_wrapped(data[\"review\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57c76f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make review col lower case\n",
    "data[\"review\"] = data.review.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8603b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek one review\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd452dd",
   "metadata": {},
   "source": [
    "## remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08670251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def remove_html(text):\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb5d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a wonderful little production. <br /><br />the filming technique is very\n",
      "unassuming- very old-time-bbc fashion and gives a comforting, and sometimes\n",
      "discomforting, sense of realism to the entire piece. <br /><br />the actors are\n",
      "extremely well chosen- michael sheen not only \"has got all the polari\" but he\n",
      "has all the voices down pat too! you can truly see the seamless editing guided\n",
      "by the references to williams' diary entries, not only is it well worth the\n",
      "watching but it is a terrificly written and performed piece. a masterful\n",
      "production about one of the great master's of comedy and his life. <br /><br\n",
      "/>the realism really comes home with the little things: the fantasy of the guard\n",
      "which, rather than use the traditional 'dream' techniques remains solid then\n",
      "disappears. it plays on our knowledge and our senses, particularly with the\n",
      "scenes concerning orton and halliwell and the sets (particularly of their flat\n",
      "with halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "print_wrapped(data.review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "843d5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae17ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a wonderful little production. the filming technique is very unassuming- very\n",
      "old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense\n",
      "of realism to the entire piece. the actors are extremely well chosen- michael\n",
      "sheen not only \"has got all the polari\" but he has all the voices down pat too!\n",
      "you can truly see the seamless editing guided by the references to williams'\n",
      "diary entries, not only is it well worth the watching but it is a terrificly\n",
      "written and performed piece. a masterful production about one of the great\n",
      "master's of comedy and his life. the realism really comes home with the little\n",
      "things: the fantasy of the guard which, rather than use the traditional 'dream'\n",
      "techniques remains solid then disappears. it plays on our knowledge and our\n",
      "senses, particularly with the scenes concerning orton and halliwell and the sets\n",
      "(particularly of their flat with halliwell's murals decorating every surface)\n",
      "are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "print_wrapped(data.review[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09768b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fdd34cd",
   "metadata": {},
   "source": [
    "## remove url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93bad93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db94c1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my youtube https://www.youtube.com/'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Check out my youtube https://www.youtube.com/\"\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a78279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my youtube'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37300542",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdfcea",
   "metadata": {},
   "source": [
    "## remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19c88a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "790cf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text: str):\n",
    "    return text.translate(str.maketrans(\"\", \"\", exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c55c2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6a69029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a73569",
   "metadata": {},
   "source": [
    "## replace chat abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68e87896",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'BAE': 'Before Anyone Else',\n",
    "    'BF': 'Boyfriend',\n",
    "    'BFF': 'Best Friends Forever',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BTW': 'By The Way',\n",
    "    'CEO': 'Used humorously, like \"CEO of sleeping late\"',\n",
    "    'DM': 'Direct Message',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FOMO': 'Fear Of Missing Out',\n",
    "    'FYA': 'For Your Action',\n",
    "    'FYI': 'For Your Information',\n",
    "    'GF': 'Girlfriend',\n",
    "    'GG': 'Good Game',\n",
    "    'GLHF': 'Good Luck, Have Fun',\n",
    "    'GOAT': 'Greatest Of All Time',\n",
    "    'GTG': 'Got To Go',\n",
    "    'HBU': 'How About You?',\n",
    "    'ICYMI': 'In Case You Missed It',\n",
    "    'IDC': \"I Don't Care\",\n",
    "    'IDGAF': \"I Don't Give A F***\",\n",
    "    'IDK': \"I Don't Know\",\n",
    "    'ILY': 'I Love You',\n",
    "    'IMHO': 'In My Humble Opinion',\n",
    "    'IMY': 'I Miss You',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'LFG': \"Let's F***ing Go\",\n",
    "    'LMAO': 'Laughing My Ass Off',\n",
    "    'LOL': 'Laugh Out Loud',\n",
    "    'NOOB': 'Newbie / Beginner',\n",
    "    'NVM': 'Never Mind',\n",
    "    'NSFW': 'Not Safe For Work',\n",
    "    'OOMF': 'One Of My Followers',\n",
    "    'OMG': 'Oh My God',\n",
    "    'OTP': 'One True Pairing',\n",
    "    'POV': 'Point Of View',\n",
    "    'RIZZ': 'Charisma / Ability to flirt (slang)',\n",
    "    'RN': 'Right Now',\n",
    "    'ROFL': 'Rolling On the Floor Laughing',\n",
    "    'SMH': 'Shaking My Head',\n",
    "    'SUS': 'Suspicious',\n",
    "    'TBH': 'To Be Honest',\n",
    "    'TBF': 'To Be Fair',\n",
    "    'TGIF': \"Thank God It's Friday\",\n",
    "    'TMI': 'Too Much Information',\n",
    "    'TT': 'TikTok',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'TTYT': 'Talk To You Tomorrow',\n",
    "    'WTF': 'What The F***',\n",
    "    'WYD': 'What You Doing?',\n",
    "    'YOLO': 'You Only Live Once'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d4ce6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abreviation_to_word(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        val = word.upper()\n",
    "        new_text.append(chat_words.get(val, word))\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a69e32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need help As Soon As Possible'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abreviation_to_word('I need help ASAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd8f65",
   "metadata": {},
   "source": [
    "## spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3947351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cfee9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2f487b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(incorrect_text).correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c222101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "138220ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'but', \"hadn't\", 'in', 'needn', 'she', \"they'll\", 'when'], 198)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_stopwords = stopwords.words(\"english\")\n",
    "eng_stopwords[:len(eng_stopwords):25], len(eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfa8d130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['au', 'mes', 'tu', 'es', 'furent', 'aurai', 'aient'], 157)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_stopwords = stopwords.words(\"french\")\n",
    "fr_stopwords[:len(fr_stopwords):25], len(fr_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8879e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str):\n",
    "    text = \" \".join([word for word in text.split() if word not in eng_stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae7d79a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'len : 208'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times\"\n",
    "f\"len : {len(sent)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30af2583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably all-time favorite movie, story selflessness, sacrifice dedication noble\n",
      "cause, preachy boring. never gets old, despite seen 15 times\n",
      "len :  141\n"
     ]
    }
   ],
   "source": [
    "print_wrapped(remove_stopwords(sent))\n",
    "print(\"len : \", len(remove_stopwords(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6b1dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7e3af00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2092b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c447f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text: str):\n",
    "    return emoji.replace_emoji(text, replace=\"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "477f1e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Python is ðŸ”¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc96443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was :face_blowing_a_kiss:'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract emoji meaning \n",
    "emoji.demojize(\"Loved the movie. It was ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ecb70",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "### 1. split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e0799771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Paris!']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokens\n",
    "\"I am going to Paris!\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d73e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to Rome',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokens\n",
    "\"I am going to Rome. I will stay there for 3 days. Let's hope the trip to be great\".split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc771e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'London!']\n",
      "['Where do you think I should go? I have 3 day holiday', '']\n"
     ]
    }
   ],
   "source": [
    "# limit with split function, punctuation is part of a word\n",
    "print(\"I am going to London!\".split())\n",
    "print(\"Where do you think I should go? I have 3 day holiday.\".split(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f0b88",
   "metadata": {},
   "source": [
    "### 2. Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda2d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Paris']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokens\n",
    "sent = \"I am going to Paris!\"\n",
    "tokens = re.findall(r\"[\\w']+\", sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86550c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do you think I should go', 'I have 3 day holiday', '']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokens\n",
    "sent = \"Where do you think I should go? I have 3 day holiday.\"\n",
    "tokens = re.compile(r'[.!?]\\s*').split(sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8d726",
   "metadata": {},
   "source": [
    "### 3. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cdb78721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a8160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Paris', '!']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation not part of the word \n",
    "word_tokenize( \"I am going to Paris!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76ee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation ends a sentence\n",
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5caac",
   "metadata": {},
   "source": [
    "### 4. Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba413873",
   "metadata": {},
   "source": [
    "- pip install -U spacy\n",
    "\n",
    "Download statistical models :\n",
    "- English\n",
    "    - python -m spacy download en_core_web_sm\n",
    "    - python -m spacy download en_core_web_md\n",
    "- French\n",
    "    - python -m spacy download fr_core_news_sm\n",
    "    - python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e905956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e6b6d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'Paris', '.', 'It', \"'s\", 'a', 'beautiful', 'city', '!']\n"
     ]
    }
   ],
   "source": [
    "# word token\n",
    "text = \"I am going to Paris. It's a beautiful city!\"\n",
    "doc = nlp(text)\n",
    "word_token = [token.text for token in doc]\n",
    "print(word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a4cb030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am going to Paris.', \"It's a beautiful city!\"]\n"
     ]
    }
   ],
   "source": [
    "# sentence token \n",
    "sentence_token = [token.text for token in doc.sents]\n",
    "print(sentence_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59e340",
   "metadata": {},
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c59f3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word to root form (not optimal, may invent a word)\n",
    "def stem_word(text: str):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab353624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_word(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31b4e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len text : 633\n",
      "\n",
      "probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl\n",
      "caus but it not preachi or bore it just never get old despit my have seen it\n",
      "some 15 or more time in the last 25 year paul luka perform bring tear to my eye\n",
      "and bett davi in one of her veri few truli sympathet role is a delight the kid\n",
      "are as grandma say more like dressedup midget than children but that onli make\n",
      "them more fun to watch and the mother slow awaken to what happen in the world\n",
      "and under her own roof is believ and startl if i had a dozen thumb theyd all be\n",
      "up for thi movi\n",
      "\n",
      "len stem text : 568\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"probably my alltime favorite movie a story of selflessness sacrifice and dedication\n",
    "to a noble cause but its not preachy or boring it just never gets old despite my having seen it \n",
    "some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and \n",
    "bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma \n",
    "says more like dressedup midgets than children but that only makes them more fun to watch and \n",
    "the mothers slow awakening to whats happening in the world and under her own roof is believable \n",
    "and startling if i had a dozen thumbs theyd all be up for this movie\"\"\"\n",
    "\n",
    "print(f\"len text : {len(text)}\")\n",
    "print()\n",
    "print_wrapped(stem_word(text))\n",
    "print()\n",
    "print(f\"len stem text : {len(stem_word(text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64706104",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "- better than stemming, root word always exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20a28eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a2642be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8819cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "62cb4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "words = [word for word in words if word not in eng_stopwords]\n",
    "words = [word for word in words if word not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a920576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word :              Lemma :             \n",
      "\n",
      "He                  He                  \n",
      "running             run                 \n",
      "eating              eat                 \n",
      "time                time                \n",
      "He                  He                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "swimming            swim                \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "print(\"{0:20}{1:20}\".format(\"Word :\", \"Lemma :\"))\n",
    "print()\n",
    "for word in words:\n",
    "    print(\"{0:20}{1:20}\".format(word, lemmatizer.lemmatize(word, pos='v')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
